{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gauta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/smartilizer/commercial-vehicles-sensor-data-set?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41.5M/41.5M [00:03<00:00, 12.1MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\gauta\\.cache\\kagglehub\\datasets\\smartilizer\\commercial-vehicles-sensor-data-set\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"smartilizer/commercial-vehicles-sensor-data-set\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scipy\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow_federated\n",
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "#import tensorflow_federated as tff\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.backend import set_floatx\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, LSTM, Dropout, Dense, Bidirectional\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\G'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\G'\n",
      "C:\\Users\\gauta\\AppData\\Local\\Temp\\ipykernel_7844\\198098718.py:2: SyntaxWarning: invalid escape sequence '\\G'\n",
      "  original_df = pd.read_csv('D:\\Github\\HeavyVehicleCBM\\Terra-D2-multi-labeled-interpolated.csv')\n"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "original_df = pd.read_csv('D:\\Github\\HeavyVehicleCBM\\Terra-D2-multi-labeled-interpolated.csv')\n",
    "# Apply only integer labels and delete label 0 \\ Also delete speed feature\n",
    "original_df = original_df[np.all((original_df.label.apply(float.is_integer), original_df.label != 0), axis=0)]\n",
    "original_df = original_df.drop(['speed'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (1164911, 6)\n"
     ]
    }
   ],
   "source": [
    "original_df['label'] = original_df['label'].astype(int) - 1\n",
    "original_df['label'].unique()\n",
    "\n",
    "df_train=original_df[:int(original_df.shape[0]*0.70)]\n",
    "df_test= original_df[int(original_df.shape[0]*0.70):]\n",
    "\n",
    "train_X0=df_train.drop(['label','time'],axis=1)\n",
    "train_Y0=df_train['label']\n",
    "train_Y0=utils.to_categorical(train_Y0,5)\n",
    "\n",
    "test_X0 = df_test.drop(['label', 'time'], axis = 1)\n",
    "test_Y0 = df_test['label']\n",
    "test_Y0 = utils.to_categorical(test_Y0, 5)\n",
    "\n",
    "print('Data shape', train_X0.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
